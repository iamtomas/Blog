# Sidekiq

> 本文通篇篇幅较长，阅读者可以根据 **你将了解到什么** 去查阅是否有想了解的内容

## 介绍

Sidekiq 是 Rails 项目中常用的后台任务处理系统，其本身提供了丰富的 API ，源代码也易于阅读，是一个轻量的异步处理组件，一般用于处理异步任务和定时任务等场景

## 安装 

网上已经有很多不错的博客分享，这里暂不详述

## 你将了解到什么

- Sidekiq 是如何启动的？
- 整个调度过程都有哪些角色参与？
- perform_async 和 perform_in 的原理
- 多线程多队列下，任务是根据什么策略分配到相关队列？又是怎么根据权重去执行队列？
- Retry 重试机制原理
- 未运行完的任务强制关闭会被怎么处理？

## 分析

### 1、Sidekiq 是如何启动的？

项目启动执行 sidekiq 时，会先去执行 **bin/sidekiq** 文件

```ruby
begin
  cli = Sidekiq::CLI.instance
  cli.parse

  integrate_with_systemd

  cli.run
rescue => e
  raise e if $DEBUG
  if Sidekiq.error_handlers.length == 0
    STDERR.puts e.message
    STDERR.puts e.backtrace.join("\n")
  else
    cli.handle_exception e
  end

  exit 1
end
```

1）创建了 **Sidekiq::CLI** 类的实例

2）调用实例方法 **#parse** 解析 Sidekiq 配置参数（如线程数量、队列和Worker的配置）

3）调用方法 **#integrate_with_systemd**，从方法名上理解是“使 sidekiq 和系统一体化，通知 systemd 状态变化”，感兴趣的可去查看[相关源码](https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/sd_notify.rb) 

4）捕获到报错后会执行 **error_handlers** 方法，源码中是这么对此解释的：

```ruby
# Register a proc to handle any error which occurs within the Sidekiq process.
#
#   Sidekiq.configure_server do |config|
#     config.error_handlers << proc {|ex,ctx_hash| MyErrorService.notify(ex, ctx_hash) }
#   end
#
# The default error handler logs errors to Sidekiq.logger.
def self.error_handlers
  options[:error_handlers]
end
```

4）最后则是执行实例方法 **#run** 开始启动，我们继续往下追踪

```ruby
require "sidekiq/launcher"
def run(boot_app: true)
  # 打印控制台信息（如欢迎语等），检查rails、redis版本及配置信息，加载等
  
  @launcher = Sidekiq::Launcher.new(options)
  
  begin
    launcher.run
    # ...
  end
end
```

上边的代码可以看出主要是实例化了 **Sidekiq::Launcher** 并调用了实例方法 **#run**，我们继续往下走

```ruby
def run
  @thread = safe_thread("heartbeat", &method(:start_heartbeat))
  @poller.start
  @manager.start
end
```

根据方法名大致猜测：一、创建线程用于心跳代码，比如定时检查sidekiq的健康状况；二、启动 poller 和 manager（后面进行解释）

至此 sidekiq 成功启动！

### 2、整个调度过程都有哪些角色参与？

我们可以继续刚才启动的最后一步继续延伸，去发现都有哪些角色在这个调度过程中起到关键作用

首先我们发现在最后启动了 @poller、@manager，可以在 **Sidekiq::Launcher** 的初始化方法 **#initialize** 中看到

```ruby
def initialize(options)
  options[:fetch] ||= BasicFetch.new(options)
  @manager = Sidekiq::Manager.new(options)
  @poller = Sidekiq::Scheduled::Poller.new
  @done = false
  @options = options
end
```

先试着追踪 **Sidekiq::Scheduled::Poller** 的实例方法 **#start**

```ruby
# lib/sidekiq/schedule/poller.rb

def start
  @thread ||= safe_thread("scheduler") {
    initial_wait

    until @done
      enqueue
      wait
    end
  	Sidekiq.logger.info("Scheduler exiting...")
  }
end
```

可以看到，这个方法里首先创建了一个线程，接着执行方法 **#initial_wait**，

```ruby
def initial_wait
  # Have all processes sleep between 5-15 seconds.  10 seconds
  # to give time for the heartbeat to register (if the poll interval is going to be calculated by the number
  # of workers), and 5 random seconds to ensure they don't all hit Redis at the same time.
  total = 0
  total += INITIAL_WAIT unless Sidekiq.options[:poll_interval_average]
  total += (5 * rand)

  @sleeper.pop(total)
  rescue Timeout::Error
end
```

在参考文档中了解到“原来只是为了避免所有进程在后续逻辑中同时触发 Redis IO 而做的设计，如果对大型系统有过架构经验的童鞋就会明白，这里其实就是为了防止类似雪崩之类的系统故障出现。让当前进程随机等待一定范围的时间，从而就可以跟其他进程错开了”

接着就到了循环体的代码，可以看到除非 **Sidekiq::Scheduled::Poller** 的实例停下，否则会一直运行，让我们看看这两个方法

```ruby
def initialize
  @enq = (Sidekiq.options[:scheduled_enq] || Sidekiq::Scheduled::Enq).new
  # ...
end

def enqueue
  @enq.enqueue_jobs
rescue => ex
  # Most likely a problem with redis networking.
  # Punt and try again at the next interval
  logger.error ex.message
  handle_exception(ex)
end
```

首先在实例方法 #enqueue 中，`@enq` 是 **Sidekiq::Scheduled::Enq**` 的实例或`:scheduled_enq` 配置项。在参考文档中了解到 “官方文档未对此参数提及以及说明，这里其实是一种策略模式的实现，用户自定义的类型必须实现 `enqueue_jobs` 方法。我估计，是 sidekiq pro 里边才会用到的配置项吧。” 所以，Sidekiq::Scheduled::Enq 我们可以理解为一种策略。继续往下看，@enq 另外执行了实例方法 **#enqueue_jobs**

```ruby
SETS = %w[retry schedule]

class Enq
  def enqueue_jobs(now = Time.now.to_f.to_s, sorted_sets = SETS)
    # A job's "score" in Redis is the time at which it should be processed.
    # Just check Redis for the set of jobs with a timestamp before now.
    Sidekiq.redis do |conn|
      sorted_sets.each do |sorted_set|
        # Get next items in the queue with scores (time to execute) <= now.
      until (jobs = conn.zrangebyscore(sorted_set, "-inf", now, limit: [0, 100])).empty?
        # We need to go through the list one at a time to reduce the risk of something
        # going wrong between the time jobs are popped from the scheduled queue and when
        # they are pushed onto a work queue and losing the jobs.
        jobs.each do |job|
          # Pop item off the queue and add it to the work queue. If the job can't be popped from
          # the queue, it's because another process already popped it so we can move on to the
          # next one.
          if conn.zrem(sorted_set, job)
            Sidekiq::Client.push(Sidekiq.load_json(job))
            Sidekiq.logger.debug { "enqueued #{sorted_set}: #{job}" }
          end
        end
      end
      end
    end
  end
end
```

**Sidekiq::Schedule::Poller** 拉取任务策略可以分解为几步：

- 从 retry 和 schedule 集合中拉取任务
- 每次拉取前100个，检查是否有计划时间小于等于当前时间的任务，若存在，则从集合中移除 job 并推送到 redis 中

接着我们回到 @poller 实例方法 **#wait**

```ruby
def initialize
  @sleeper = ConnectionPool::TimedStack.new
  # ...
end

private

def wait
  @sleeper.pop(random_poll_interval)
rescue Timeout::Error
  # expected
rescue => ex
  # if poll_interval_average hasn't been calculated yet, we can
  # raise an error trying to reach Redis.
  logger.error ex.message
  handle_exception(ex)
  sleep 5
end

def random_poll_interval
  # We want one Sidekiq process to schedule jobs every N seconds.  We have M processes
  # and **don't** want to coordinate.
  #
  # So in N*M second timespan, we want each process to schedule once.  The basic loop is:
  #
  # * sleep a random amount within that N*M timespan
  # * wake up and schedule
  #
  # We want to avoid one edge case: imagine a set of 2 processes, scheduling every 5 seconds,
  # so N*M = 10.  Each process decides to randomly sleep 8 seconds, now we've failed to meet
  # that 5 second average. Thankfully each schedule cycle will sleep randomly so the next
  # iteration could see each process sleep for 1 second, undercutting our average.
  #
  # So below 10 processes, we special case and ensure the processes sleep closer to the average.
  # In the example above, each process should schedule every 10 seconds on average. We special
  # case smaller clusters to add 50% so they would sleep somewhere between 5 and 15 seconds.
  # As we run more processes, the scheduling interval average will approach an even spread
  # between 0 and poll interval so we don't need this artifical boost.
  #
  if process_count < 10
    # For small clusters, calculate a random interval that is ±50% the desired average.
    poll_interval_average * rand + poll_interval_average.to_f / 2
  else
    # With 10+ processes, we should have enough randomness to get decent polling
    # across the entire timespan
    poll_interval_average * rand
  end
end
```

以上代码主要是起到休眠的作用，它依赖于 Ruby Gem [connection_pool](https://github.com/mperham/connection_pool/blob/master/lib/connection_pool/timed_stack.rb) ，其方法 **pop** 会阻塞当前代码的执行，正是利用这点实现 Sidekiq 的休眠。另外需要补充的就是实例方法 **#random_poll_interval**，通过大段的注释可以看出这个休眠时间是个注意点，借鉴参考文档的解释“大概意思是，sidekiq 为了避免在进程重启后，有大量的进程同时密集地访问 redis，所以设计了这个机制，就是每个进程对定时任务的检查都是按照一个公式来计算的，保证每个进程两次检查之间的平均休眠时间能够在一个范围内动态变化，从而将所有进程的 Redis IO 均匀错开。”

> 至此，@poller 的过程大致过了遍，@poller 在这个过程充当的是 **定时任务拉取器** 角色，负责在一定时间范围内不定时检查定时任务(scheduled)以及重试任务(retry)，将计划时间已经超过当前时间的任务追加到各自对应任务队列中

启动过程最后一步除了**Sidekiq::Manager::Poller** 的实例方法 **#start** ，还有 **Sidekiq::Manager** 的实例方法 **#start** ，让我们也大致过一下

```ruby
def initialize(options = {})
  logger.debug { options.inspect }
  @options = options
  @count = options[:concurrency] || 10
  raise ArgumentError, "Concurrency of #{@count} is not supported" if @count < 1

  @done = false
  @workers = Set.new
  @count.times do
    @workers << Processor.new(self, options)
  end
  @plock = Mutex.new
end

def start
  @workers.each do |x|
    x.start
  end
end
```

可以看到多了 **Sidekiq::Processor** 实例，它的个数取决于 options[:concurrency] 即 sidekiq 的配置线程数， **Sidekiq::Manager** 起到的作用就是调用管理所有的 worker ，我们继续往下走，看看 **Sidekiq::Processor** 的实例方法 **#start**  

```ruby
# lib/sidekiq/manager.rb
def start
  @thread ||= safe_thread("processor", &method(:run))
end

private unless $TESTING

def run
  process_one until @done
    @mgr.processor_stopped(self)
  rescue Sidekiq::Shutdown
    @mgr.processor_stopped(self)
  rescue Exception => ex
    @mgr.processor_died(self, ex)
  end
end
```

可以看出， @manger 为每个 worker 创建各自的线程并执行私有方法 **#run** ，细心的小伙伴可以看到线程结束取决于 **@done** ，这个信号处理机制是几时引入的？在这篇笔记中就不细述了，感兴趣的小伙伴可以研究。回到正题，如果线程没结束，就会一直执行实例方法 **#process_one** 

```ruby
##
# The Processor is a standalone thread which:
#
# 1. fetches a job from Redis
# 2. executes the job
#   a. instantiate the Worker
#   b. run the middleware chain
#   c. call #perform
#
# A Processor can exit due to shutdown (processor_stopped)
# or due to an error during job execution (processor_died)
#
# If an error occurs in the job execution, the
# Processor calls the Manager to create a new one
# to replace itself and exits.
#
class Processor
  #...
  
  def process_one
    @job = fetch
    process(@job) if @job
    @job = nil
  end
  
  # ...
end
```

从注释中我们能了解到， **Sidekiq::Processor** 负责去执行指定的任务，具体过程感兴趣的同学也能到 [相关源码](https://github.com/mperham/sidekiq/blob/6adde6b346f6ad6d505bd51c8e70fc2bc89e89f6/lib/sidekiq/processor.rb) 了解，这暂不细述

综上所述，我们能了解到整个调度过程都有  **Sidekiq::Schedule::Poller**、  **Sidekiq::Manager** 、 **Sidekiq::Processor** 这三个角色，可以对它们命名为 定时任务拉取器 、worker 管理器 、worker

### 3、perform_async 和 perform_in 的原理

首先思考一个问题，这两个方法是几时引入的？

举个例子，编写定时任务：

```ruby
class XxxWorker
  include Sidekiq::Worker
  include Sidetiq::Schedulable
  recurrence do
    # ...
  end
  def perform()
    # ...
  end
end

# 使用方式
$ rails c
$ XxxWorker.perform_async('tomas', 1)
$ XxxWorker.perform_in(1.minutes, 'tomas', 1)
```

可以看到一开始引入了 **Sidekiq::Worker** ，其提供了方法 **perform_async** 和 **perform_in** ，源码如下

```ruby
# lib/sidekiq/worker.rb

def perform_async(*args)
  client_push("class" => self, "args" => args)
end

# +interval+ must be a timestamp, numeric or something that acts
#   numeric (like an activesupport time interval).
def perform_in(interval, *args)
  int = interval.to_f
  now = Time.now.to_f
  ts = (int < 1_000_000_000 ? now + int : int)

  item = {"class" => self, "args" => args}

  # Optimization to enqueue something now that is scheduled to go out now or in the past
  item["at"] = ts if ts > now

  client_push(item)
end

def client_push(item) # :nodoc:
  pool = Thread.current[:sidekiq_via_pool] || get_sidekiq_options["pool"] || Sidekiq.redis_pool
  stringified_item = item.transform_keys(&:to_s)

  Sidekiq::Client.new(pool).push(stringified_item)
end
```

两者的区别在于多了个参数 **at** ，最后讲下方法 **#client_push** ， 前面我们介绍到了 **Sidekiq::Schedule::Poller** 会从 “retry” 和 “schedule” 队列去拉取任务并推入到 redis 有序集合中，最后交由 **Sidekiq::Processer** 从集合中获取并处理这些 job，这与 `Sidekiq::Client.new(pool).push(stringified_item)` 一个道理，让我看看具体是如何推入到redis中，具体核心代码如下：

```ruby
# lib/sidekiq/client.rb

def atomic_push(conn, payloads)
  if payloads.first.key?("at")
    conn.zadd("schedule", payloads.map { |hash|
      at = hash.delete("at").to_s
      [at, Sidekiq.dump_json(hash)]
      })
  else
    queue = payloads.first["queue"]
    now = Time.now.to_f
    to_push = payloads.map { |entry|
      entry["enqueued_at"] = now
      Sidekiq.dump_json(entry)
      }
    conn.sadd("queues", queue)
    conn.lpush("queue:#{queue}", to_push)
  end
end
```





## 参考

[sidekiq任务调度流程分析](https://segmentfault.com/a/1190000007321951)

[sidekiq设计浅析](https://www.yuque.com/chenxiaodong-hvqvm/zbb1us/sng3sg)

## 





## 
