# Sidekiq

> 本文通篇篇幅较长，阅读者可以根据 **你将了解到什么** 去查阅是否有想了解的内容

## 介绍

Sidekiq 是 Rails 项目中常用的后台任务处理系统，其本身提供了丰富的 API ，源代码也易于阅读，是一个轻量的异步处理组件，一般用于处理异步任务和定时任务等场景

## 安装 

网上已经有很多不错的博客分享，这里暂不详述

## 你将了解到什么

- Sidekiq 是如何启动的？
- 整个调度过程都有哪些角色参与？
- perform_async 和 perform_in 的原理
- 如何根据权重去执行队列？
- Retry 重试机制原理

## 分析

### 1、Sidekiq 是如何启动的？

项目启动执行 sidekiq 时，会先去执行 `bin/sidekiq` 文件

```ruby
begin
  cli = Sidekiq::CLI.instance
  cli.parse

  integrate_with_systemd

  cli.run
rescue => e
  raise e if $DEBUG
  if Sidekiq.error_handlers.length == 0
    STDERR.puts e.message
    STDERR.puts e.backtrace.join("\n")
  else
    cli.handle_exception e
  end

  exit 1
end
```

1）创建了 `Sidekiq::CLI` 类的实例

2）调用实例方法 `#parse` 解析 Sidekiq 配置参数（如线程数量、队列和Worker的配置）

3）调用方法 `#integrate_with_systemd`，从方法名上理解是“使 sidekiq 和系统一体化，通知 systemd 状态变化”，感兴趣的可去查看[相关源码](https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/sd_notify.rb) 

4）捕获到报错后会执行 `error_handlers` 方法，源码中是这么对此解释的：

```ruby
# Register a proc to handle any error which occurs within the Sidekiq process.
#
#   Sidekiq.configure_server do |config|
#     config.error_handlers << proc {|ex,ctx_hash| MyErrorService.notify(ex, ctx_hash) }
#   end
#
# The default error handler logs errors to Sidekiq.logger.
def self.error_handlers
  options[:error_handlers]
end
```

4）最后则是执行实例方法 `#run` 开始启动，我们继续往下追踪

```ruby
require "sidekiq/launcher"
def run(boot_app: true)
  # 打印控制台信息（如欢迎语等），检查rails、redis版本及配置信息，加载等
  
  @launcher = Sidekiq::Launcher.new(options)
  
  begin
    launcher.run
    # ...
  end
end
```

上边的代码可以看出主要是实例化了 `Sidekiq::Launcher` 并调用了实例方法 `#run`，我们继续往下走

```ruby
def run
  @thread = safe_thread("heartbeat", &method(:start_heartbeat))
  @poller.start
  @manager.start
end
```

根据方法名大致猜测：一、创建线程用于心跳代码，比如定时检查 sidekiq 的健康状况；二、启动 poller 和 manager（后面进行解释）

至此 sidekiq 成功启动！

### 2、整个调度过程都有哪些角色参与？

我们可以继续刚才启动的最后一步继续延伸，去发现都有哪些角色在这个调度过程中起到关键作用

首先我们发现在最后启动了 @poller、@manager，可以在 `Sidekiq::Launcher` 的初始化方法 `#initialize` 中看到

```ruby
def initialize(options)
  options[:fetch] ||= BasicFetch.new(options)
  @manager = Sidekiq::Manager.new(options)
  @poller = Sidekiq::Scheduled::Poller.new
  @done = false
  @options = options
end
```

先试着追踪 `Sidekiq::Scheduled::Poller` 的实例方法 `#start`

```ruby
# lib/sidekiq/schedule/poller.rb

def start
  @thread ||= safe_thread("scheduler") {
    initial_wait

    until @done
      enqueue
      wait
    end
  	Sidekiq.logger.info("Scheduler exiting...")
  }
end
```

可以看到，这个方法里首先创建了一个线程，接着执行方法 `#initial_wait`，

```ruby
def initial_wait
  # Have all processes sleep between 5-15 seconds.  10 seconds
  # to give time for the heartbeat to register (if the poll interval is going to be calculated by the number
  # of workers), and 5 random seconds to ensure they don't all hit Redis at the same time.
  total = 0
  total += INITIAL_WAIT unless Sidekiq.options[:poll_interval_average]
  total += (5 * rand)

  @sleeper.pop(total)
  rescue Timeout::Error
end
```

在参考文档中了解到“原来只是为了避免所有进程在后续逻辑中同时触发 Redis IO 而做的设计，如果对大型系统有过架构经验的童鞋就会明白，这里其实就是为了防止类似雪崩之类的系统故障出现。让当前进程随机等待一定范围的时间，从而就可以跟其他进程错开了”

接着就到了循环体的代码，可以看到除非 `Sidekiq::Scheduled::Poller` 的实例停下，否则会一直运行，让我们看看这两个方法

```ruby
def initialize
  @enq = (Sidekiq.options[:scheduled_enq] || Sidekiq::Scheduled::Enq).new
  # ...
end

def enqueue
  @enq.enqueue_jobs
rescue => ex
  # Most likely a problem with redis networking.
  # Punt and try again at the next interval
  logger.error ex.message
  handle_exception(ex)
end
```

首先在实例方法 #enqueue 中，`@enq` 是 `Sidekiq::Scheduled::Enq` 的实例或  :scheduled_enq 配置项。在参考文档中了解到 “官方文档未对此参数提及以及说明，这里其实是一种策略模式的实现，用户自定义的类型必须实现 `enqueue_jobs` 方法。我估计，是 sidekiq pro 里边才会用到的配置项吧。” 所以，`Sidekiq::Scheduled::Enq` 我们可以理解为它的策略。继续往下看，@enq 另外执行了实例方法 `#enqueue_jobs`

```ruby
SETS = %w[retry schedule]

class Enq
  def enqueue_jobs(now = Time.now.to_f.to_s, sorted_sets = SETS)
    # A job's "score" in Redis is the time at which it should be processed.
    # Just check Redis for the set of jobs with a timestamp before now.
    Sidekiq.redis do |conn|
      sorted_sets.each do |sorted_set|
        # Get next items in the queue with scores (time to execute) <= now.
      until (jobs = conn.zrangebyscore(sorted_set, "-inf", now, limit: [0, 100])).empty?
        # We need to go through the list one at a time to reduce the risk of something
        # going wrong between the time jobs are popped from the scheduled queue and when
        # they are pushed onto a work queue and losing the jobs.
        jobs.each do |job|
          # Pop item off the queue and add it to the work queue. If the job can't be popped from
          # the queue, it's because another process already popped it so we can move on to the
          # next one.
          if conn.zrem(sorted_set, job)
            Sidekiq::Client.push(Sidekiq.load_json(job))
            Sidekiq.logger.debug { "enqueued #{sorted_set}: #{job}" }
          end
        end
      end
      end
    end
  end
end
```

`Sidekiq::Schedule::Poller` 拉取任务策略可以分解为几步：

- 从 retry 和 schedule 集合中拉取任务
- 每次拉取前100个，检查是否有计划时间小于等于当前时间的任务，若存在，则从集合中移除 job 并推送到 redis 中

接着我们回到 @poller 实例方法 `#wait`

```ruby
def initialize
  @sleeper = ConnectionPool::TimedStack.new
  # ...
end

private

def wait
  @sleeper.pop(random_poll_interval)
rescue Timeout::Error
  # expected
rescue => ex
  # if poll_interval_average hasn't been calculated yet, we can
  # raise an error trying to reach Redis.
  logger.error ex.message
  handle_exception(ex)
  sleep 5
end

def random_poll_interval
  # We want one Sidekiq process to schedule jobs every N seconds.  We have M processes
  # and **don't** want to coordinate.
  #
  # So in N*M second timespan, we want each process to schedule once.  The basic loop is:
  #
  # * sleep a random amount within that N*M timespan
  # * wake up and schedule
  #
  # We want to avoid one edge case: imagine a set of 2 processes, scheduling every 5 seconds,
  # so N*M = 10.  Each process decides to randomly sleep 8 seconds, now we've failed to meet
  # that 5 second average. Thankfully each schedule cycle will sleep randomly so the next
  # iteration could see each process sleep for 1 second, undercutting our average.
  #
  # So below 10 processes, we special case and ensure the processes sleep closer to the average.
  # In the example above, each process should schedule every 10 seconds on average. We special
  # case smaller clusters to add 50% so they would sleep somewhere between 5 and 15 seconds.
  # As we run more processes, the scheduling interval average will approach an even spread
  # between 0 and poll interval so we don't need this artifical boost.
  #
  if process_count < 10
    # For small clusters, calculate a random interval that is ±50% the desired average.
    poll_interval_average * rand + poll_interval_average.to_f / 2
  else
    # With 10+ processes, we should have enough randomness to get decent polling
    # across the entire timespan
    poll_interval_average * rand
  end
end
```

以上代码主要是起到休眠的作用，它依赖于 Ruby Gem [connection_pool](https://github.com/mperham/connection_pool/blob/master/lib/connection_pool/timed_stack.rb) ，其方法 `pop` 会阻塞当前代码的执行，正是利用这点实现 Sidekiq 的休眠。另外需要补充的就是实例方法 `#random_poll_interval`，通过大段的注释可以看出这个休眠时间是个注意点，借鉴参考文档的解释“大概意思是，sidekiq 为了避免在进程重启后，有大量的进程同时密集地访问 redis，所以设计了这个机制，就是每个进程对定时任务的检查都是按照一个公式来计算的，保证每个进程两次检查之间的平均休眠时间能够在一个范围内动态变化，从而将所有进程的 Redis IO 均匀错开。”

> 至此，@poller 的过程大致过了遍，@poller 在这个过程充当的是 **定时任务拉取器** 角色，负责在一定时间范围内不定时检查定时任务(scheduled)以及重试任务(retry)，将计划时间已经超过当前时间的任务追加到各自对应任务队列中

启动过程最后一步除了 `Sidekiq::Manager::Poller` 的实例方法 `#start `，还有 `Sidekiq::Manager` 的实例方法 `#start` ，让我们也大致过一下

```ruby
def initialize(options = {})
  logger.debug { options.inspect }
  @options = options
  @count = options[:concurrency] || 10
  raise ArgumentError, "Concurrency of #{@count} is not supported" if @count < 1

  @done = false
  @workers = Set.new
  @count.times do
    @workers << Processor.new(self, options)
  end
  @plock = Mutex.new
end

def start
  @workers.each do |x|
    x.start
  end
end
```

可以看到多了 `Sidekiq::Processor` 实例，它的个数取决于 `options[:concurrency]` 即 sidekiq 的配置线程数， `Sidekiq::Manager` 起到的作用就是调用管理所有的 worker ，我们继续往下走，看看 `Sidekiq::Processor` 的实例方法 `#start  `

```ruby
# lib/sidekiq/manager.rb
def start
  @thread ||= safe_thread("processor", &method(:run))
end

private unless $TESTING

def run
  process_one until @done
    @mgr.processor_stopped(self)
  rescue Sidekiq::Shutdown
    @mgr.processor_stopped(self)
  rescue Exception => ex
    @mgr.processor_died(self, ex)
  end
end
```

可以看出， @manger 为每个 worker 创建各自的线程并执行私有方法 `#run` ，细心的小伙伴可以看到线程结束取决于 `@done` ，这个信号处理机制是几时引入的？在这篇笔记中就不细述了，感兴趣的小伙伴可以研究。回到正题，如果线程没结束，就会一直执行实例方法 `#process_one` 

```ruby
##
# The Processor is a standalone thread which:
#
# 1. fetches a job from Redis
# 2. executes the job
#   a. instantiate the Worker
#   b. run the middleware chain
#   c. call #perform
#
# A Processor can exit due to shutdown (processor_stopped)
# or due to an error during job execution (processor_died)
#
# If an error occurs in the job execution, the
# Processor calls the Manager to create a new one
# to replace itself and exits.
#
class Processor
  #...
  
  def process_one
    @job = fetch
    process(@job) if @job
    @job = nil
  end
  
  # ...
end
```

从注释中我们能了解到， `Sidekiq::Processor` 负责去执行指定的任务，具体过程感兴趣的同学也能到 [相关源码](https://github.com/mperham/sidekiq/blob/6adde6b346f6ad6d505bd51c8e70fc2bc89e89f6/lib/sidekiq/processor.rb) 了解，这暂不细述

综上所述，我们能了解到整个调度过程都有  `Sidekiq::Schedule::Poller`、  `Sidekiq::Manager` 、 `Sidekiq::Processor` 这三个角色，可以对它们命名为 定时任务拉取器 、worker 管理器 、worker

### 3、perform_async 和 perform_in 的原理

首先思考一个问题，这两个方法是几时引入的？

举个例子，编写定时任务：

```ruby
class XxxWorker
  include Sidekiq::Worker
  include Sidetiq::Schedulable
  recurrence do
    # ...
  end
  def perform()
    # ...
  end
end

# 使用方式
$ rails c
$ XxxWorker.perform_async('tomas', 1)
$ XxxWorker.perform_in(1.minutes, 'tomas', 1)
```

可以看到一开始引入了 `Sidekiq::Worker` ，其提供了方法 `perform_async` 和 `perform_in` ，源码如下

```ruby
# lib/sidekiq/worker.rb

def perform_async(*args)
  client_push("class" => self, "args" => args)
end

# +interval+ must be a timestamp, numeric or something that acts
#   numeric (like an activesupport time interval).
def perform_in(interval, *args)
  int = interval.to_f
  now = Time.now.to_f
  ts = (int < 1_000_000_000 ? now + int : int)

  item = {"class" => self, "args" => args}

  # Optimization to enqueue something now that is scheduled to go out now or in the past
  item["at"] = ts if ts > now

  client_push(item)
end

def client_push(item) # :nodoc:
  pool = Thread.current[:sidekiq_via_pool] || get_sidekiq_options["pool"] || Sidekiq.redis_pool
  stringified_item = item.transform_keys(&:to_s)

  Sidekiq::Client.new(pool).push(stringified_item)
end
```

两者的区别在于多了个参数 **at** ，最后讲下方法 `#client_push` ， 前面我们介绍到了 `Sidekiq::Schedule::Poller` 会从 “retry” 和 “schedule” 队列去拉取任务并推入到 redis 有序集合中，最后交由 `Sidekiq::Processer` 从集合中获取并处理这些 job，这与 `Sidekiq::Client.new(pool).push(stringified_item)` 一个道理，让我看看具体是如何推入到redis中，具体核心代码如下：

```ruby
# lib/sidekiq/client.rb

def atomic_push(conn, payloads)
  if payloads.first.key?("at")
    conn.zadd("schedule", payloads.map { |hash|
      at = hash.delete("at").to_s
      [at, Sidekiq.dump_json(hash)]
      })
  else
    queue = payloads.first["queue"]
    now = Time.now.to_f
    to_push = payloads.map { |entry|
      entry["enqueued_at"] = now
      Sidekiq.dump_json(entry)
      }
    conn.sadd("queues", queue)
    conn.lpush("queue:#{queue}", to_push)
  end
end
```

### 如何根据权重去执行队列？

可通过命令行或是配置文件的方式配置权重

```ruby
# config/sidekiq.yml
:queues:
  - [critical, 2] # 使用数组的形式写, 第一个参数为打开的 queue 的名称, 第二个为优先级
  - default # 写在队列参数中的, 表示让 sidekiq 处理这个 queue
  - low

$ sidekiq -q critical -q default -q low
```

在启动 sidekiq 时，会在 `bin/sidekiq` 文件中的解析传入的参数，因为层层调用，仅贴解析参数的最核心代码

```ruby
def parse_queue(opts, queue, weight = nil)
  opts[:queues] ||= []
  opts[:strict] = true if opts[:strict].nil?
  raise ArgumentError, "queues: #{queue} cannot be defined twice" if opts[:queues].include?(queue)
  [weight.to_i, 1].max.times { opts[:queues] << queue }
  opts[:strict] = false if weight.to_i > 0
end
```

opts[:queues]：队列数组

opts[:strict] ：表示队列是否按顺序，如果其中有一个队列有权重配置，则 `opts[:strict] = false`

Processer 会不断从 redis 中查找job并将其处理，其中会去执行 `lib/sidekiq/fetch.rb` 的实例方法 `#retrieve_work` ，

当配有权重时，会先打乱再去重：`@queues.shuffle!.uniq` ，最后执行 redis 的 brpop 

```ruby
def initialize(options)
  raise ArgumentError, "missing queue list" unless options[:queues]
  @options = options
  @strictly_ordered_queues = !!@options[:strict]
  @queues = @options[:queues].map { |q| "queue:#{q}" }
  if @strictly_ordered_queues
    @queues.uniq!
    @queues << TIMEOUT
  end
end

def retrieve_work
  qs = queues_cmd
  # 4825 Sidekiq Pro with all queues paused will return an
  # empty set of queues with a trailing TIMEOUT value.
  if qs.size <= 1
    sleep(2)
    return nil
  end

  work = Sidekiq.redis { |conn| conn.brpop(*qs) }
  UnitOfWork.new(*work) if work
end

# Creating the Redis#brpop command takes into account any
# configured queue weights. By default Redis#brpop returns
# data from the first queue that has pending elements. We
# recreate the queue command each time we invoke Redis#brpop
# to honor weights and avoid queue starvation.
def queues_cmd
  if @strictly_ordered_queues
    @queues
  else
    queues = @queues.shuffle!.uniq
    queues << TIMEOUT
    queues
  end
end
```



### Retry 重试机制原理

sidekiq 的重试机制是基于中间件实现的，对中间件感兴趣的小伙伴可以去阅读源码，这暂不细述。让我们来看看核心方法 `#attempt_retry`

```ruby
private

# Note that +worker+ can be nil here if an error is raised before we can
# instantiate the worker instance.  All access must be guarded and
# best effort.
def attempt_retry(worker, msg, queue, exception)
  max_retry_attempts = retry_attempts_from(msg["retry"], @max_retries)

  msg["queue"] = (msg["retry_queue"] || queue)

  m = exception_message(exception)
  if m.respond_to?(:scrub!)
    m.force_encoding("utf-8")
    m.scrub!
  end

  msg["error_message"] = m
  msg["error_class"] = exception.class.name
  count = if msg["retry_count"]
  msg["retried_at"] = Time.now.to_f
  msg["retry_count"] += 1
else
  msg["failed_at"] = Time.now.to_f
  msg["retry_count"] = 0
end

if msg["backtrace"]
  lines = if msg["backtrace"] == true
  exception.backtrace
else
  exception.backtrace[0...msg["backtrace"].to_i]
end

msg["error_backtrace"] = compress_backtrace(lines)
end

if count < max_retry_attempts
  delay = delay_for(worker, count, exception)
  # Logging here can break retries if the logging device raises ENOSPC #3979
  # logger.debug { "Failure! Retry #{count} in #{delay} seconds" }
  retry_at = Time.now.to_f + delay
  payload = Sidekiq.dump_json(msg)
  Sidekiq.redis do |conn|
    conn.zadd("retry", retry_at.to_s, payload)
  end
else
  # Goodbye dear message, you (re)tried your best I'm sure.
  retries_exhausted(worker, msg, exception)
end
end
```

主要做了几步：

- 会为当前的 `job` 添加一些额外的参数，如 `error_message、error_class、backtrace` 等
- 查是否已经超过重试次数，若超过了，则被放到 dead_set ，若没超过，则计算下次执行时间并放入 retry 的集合中

## 保留疑问

- 信号机制
- 中间件
- 未运行完的任务强制关闭会被怎么处理？

## 参考

[sidekiq任务调度流程分析](https://segmentfault.com/a/1190000007321951)

[sidekiq设计浅析](https://www.yuque.com/chenxiaodong-hvqvm/zbb1us/sng3sg)

## 





## 
